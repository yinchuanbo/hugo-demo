---
title: "NodeJs 爬虫程序集"
date: 2023-06-07T16:07:58+08:00
---

### 一、前言

网络爬虫（又称为网页蜘蛛，网络机器人，在 FOAF 社区中间，更经常的称为网页追逐者），是一种按照一定的规则，自动地抓取万维网信息的程序或者脚本。另外一些不常使用的名字还有蚂蚁、自动索引、模拟程序或者蠕虫。

目前几乎所有语言都可以实现爬虫，较为流行的有 NodeJs、python 等。 简单场景使用 nodejs 即可，专业级的爬虫考虑的比较多，像多线程、吞吐量、分布式爬取、拓展性等，应该使用 python 做爬虫更合适。

本文简单介绍 nodejs 爬虫的使用，并实现几个较为简单的程序作为小玩具，只为学习交流。**不要恶意爬取网站数据，和谐网络环境需要大家共同维护。**

[nodejs-spider](https://github.com/Zuojiangtao/nodejs-spider)

### 二、开发简述

爬取数据一般简单来说就是  `目标请求` -> `获取数据` -> `处理数据`  这几个阶段。

获取数据一般有直接**从接口获取**、**解析 JS 构造运行环境获取**和**页面解析获取**等几种方式。

从接口获取是最简单的，到目标网站直接 F12 找到相应接口，然后构造请求函数获取数据，最后将数据处理。

有的网站的页面可能是混合生成，比如某些部分是异步获取 JS 再动态生成对应内容，这时需要 JS 引擎对异步 JS 内容做解析才能获取数据。

有些页面是服务端渲染生成的，这种情况要对目标网站做页面解析，可查看页面 DOM 结构，然后获取相应数据。

### 三、程序实现

### 1\. 美女图片

我们通过**爬取接口的方式**实现获取数据并下载图片保存到本地。

- 设置接口相关参数(通过 axios)；
- 通过接口获取数据(这里是图片的 url)；
- 将图片下载到本地(通过 download)；

对于这个美女网站我们可以直接爬取接口来获取图片 url，然后将图片保存。结果如图：

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ee35d767b84d4da994c8662c5830f5b8~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

完整源代码请看  [beauty.js](https://link.zhihu.com/?target=https%3A//github.com/Zuojiangtao/nodejs-spider/blob/main/src/beauty.js)。

### 2\. 微博/百度热搜

有的网站并不是通过接口的方式来获取数据，比如服务端渲染的页面。这时我们可以通过**页面解析的方式**来爬取数据。

- 百度热搜

像[百度热搜](https://link.zhihu.com/?target=https%3A//top.baidu.com/board%3Fplatform%3Dpc%26sa%3Dpcindex_a_right)，我们通过分析页面 DOM 结构可知热搜数据位于  `.theme-hot[theme="realtime"] .list_1EDla a` ，通过  `cheerio`  框架来使用选择器获取热搜文案及其他数据。
然后可以直接使用 nodejs 内置工具函数  `fs.writeFileSync`  来将数据保存到本地。结果如下：

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/fc2826b7e4534854b7e282eee7849bac~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

baidu_realtime_hot.json

可以运行  `npm run baidu-hot`  然后在  `static/baidu_realtime_hot.json`  查看。

- 微博热搜

有些网站为了防爬虫加了一些校验，如[微博热搜](https://link.zhihu.com/?target=https%3A//s.weibo.com/top/summary%3Fcate%3Drealtimehot)需要设置  `Cookie`。一般来说比较简单，我们 F12 查看可以通过分析看文件请求  `Request Headers`  字段是否有校验字段，通常是 cookie 和 token 这种。
可以对微博热搜设置 headers 来通过校验。结果如下：

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/b7ec6b5720b3418595241ebe6c214171~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

weibo_realtime_hot.json

可以运行  `npm run weibo-hot`  然后在  `static/weibo_realtime_hot.json`  查看。

> cheerio 作为选择器使用要处理，cheerio.load(res.data)。具体使用请看：[github.com/cheeriojs/c…](https://link.zhihu.com/?target=https%3A//github.com/cheeriojs/cheerio)

### 3\. 天天基金

同样的，这个程序也是通过**抓取接口形式**来爬取数据。规则是爬取  `今年前50，资金规模不超过10亿`  的基金。

- 通过 axios 获取接口数据;
- 并对获取到的数据做处理，将会得到  `var rankData ={ /.../ }`  形式数据;
- 使用  `node-xlsx`  将\[\[str, str, str\], \[str, str, str\]\]形式数据转换为 buffer;
- 将 buffer 通过 fs 模块下载到本地，这里是指定了下载位置到  `/static`;

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a613e6154d6c45dfa61b0e02d0de9eb0~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

天天基金 excel

源码请看  [src/tiantian-fund.js](https://link.zhihu.com/?target=https%3A//github.com/Zuojiangtao/nodejs-spider/blob/main/src/tiantian-fund.js)。

### **4\. 国家统计局**

通过**爬取接口的方式**获取相应的数据，并生成 xlsx 文件。这里我爬取了  `国民经济核算最近6季度的数据`。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/6484ed7753464ef9b9017969a1fd4faa~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

源码请看  [src/national_data.js](https://link.zhihu.com/?target=https%3A//github.com/Zuojiangtao/nodejs-spider/blob/main/src/national_data.js)。

### **5\. 高清素材**

通过**爬取接口的方式**获取相应高清图片素材，这个网站有 token 校验，要自己登录获取相应字段值  `Sentry-Trace`  和  `Cookie`。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/049be156f17c49ee90d415923972fada~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

源码请看  [src/pexels.js](https://link.zhihu.com/?target=https%3A//github.com/Zuojiangtao/nodejs-spider/blob/main/src/pexels.js)。

### **6\. 4k 高清壁纸**

通过**页面分析的方式**获取相应高清壁纸。

![](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/29f520bc068e4924aad2830524d5b311~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

源码请看  [src/netbian.js](https://link.zhihu.com/?target=https%3A//github.com/Zuojiangtao/nodejs-spider/blob/main/src/netbian.js)。

### 四、项目本地预览

项目已开源，欢迎点赞: [一款基于 nodejs 的爬虫程序集](https://link.zhihu.com/?target=https%3A//github.com/Zuojiangtao/nodejs-spider)

### 1\. Clone repo

```js
git clone --depth=1 https://github.com/Zuojiangtao/nodejs-spider.git my-project
cd my-project
```

### 2\. 安装依赖

```js
yarn install
```

### 3\. 运行爬虫指令

```js
yarn beauty // 爬取美女图片

yarn weibo-hot // 爬取微博热搜

yarn baidu-hot // 爬取百度热搜

yarn tiantian-fund // 爬取天天基金筛选数据

yarn national-data // 爬取国家统计局经济核算数据

yarn pexels // 爬取高清素材图片

yarn netbian // 爬取4k高清壁纸
```

### 4\. 内容查看

所有生成内容均在  `/static`  下找到。

### 五、常用模块推荐

### 1\. 下载文件常用模块

1.  可使用内置模块 ‘fs’ ;
2.  使用第三方插件 ‘node-downloader-helper’ ;
3.  使用第三方插件 ‘download’ ;

### 2\. 获取数据常用模块

1.  如果 node 版本 17.5.0 以上，可以使用 fetch 模块;
2.  使用 axios、request、superagent 等第三方插件;
3.  使用内置模块 ‘http’;

### 3\. 其他优秀依赖及模块推荐

1.  一款轻量级 nodejs 爬虫工具：[node-crawler](https://link.zhihu.com/?target=https%3A//github.com/bda-research/node-crawler);
2.  一个验证码相关工具：[node-tesseract](https://link.zhihu.com/?target=https%3A//github.com/desmondmorris/node-tesseract);
3.  爬虫定时爬取：[node-schedule](https://link.zhihu.com/?target=https%3A//github.com/node-schedule/node-schedule);
4.  将 markdown 文件转成 PDF 文件：[markdown-pdf](https://link.zhihu.com/?target=https%3A//github.com/alanshaw/markdown-pdf);
5.  xlsx：[node-xlsx](https://link.zhihu.com/?target=https%3A//github.com/mgcrea/node-xlsx);
6.  csv：[node-csv](https://link.zhihu.com/?target=https%3A//github.com/adaltas/node-csv);
7.  模拟用户在浏览器中进行的多种操作和行为: [puppeteer](https://link.zhihu.com/?target=https%3A//puppeteer.bootcss.com/);
8.  其他依赖资源汇总：[awesome-nodejs](https://link.zhihu.com/?target=https%3A//github.com/sindresorhus/awesome-nodejs);

### 六、参考资料

- [网络爬虫-百度百科](https://link.zhihu.com/?target=https%3A//baike.baidu.com/item/%25E7%25BD%2591%25E7%25BB%259C%25E7%2588%25AC%25E8%2599%25AB/5162711%3Ffromtitle%3D%25E7%2588%25AC%25E8%2599%25AB%26fromid%3D22046949%26fr%3Daladdin)
- [Node.js 爬虫相关模块小整合](https://link.zhihu.com/?target=https%3A//juejin.cn/post/6844903449054674952)
